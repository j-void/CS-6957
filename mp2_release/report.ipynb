{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import scripts.state as state\n",
    "import config as cfg\n",
    "import data_loader as dl\n",
    "from model import *\n",
    "import copy\n",
    "from scripts.evaluate import compute_metrics\n",
    "import eval_utils as util\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pose_set = dl.convert_to_labels(dl.get_file_contents(cfg.pose_set_file))\n",
    "tagset = dl.convert_to_labels(dl.get_file_contents(cfg.tagset_file))\n",
    "reverse_tagset = dict(zip(tagset.values(), tagset.keys()))\n",
    "glove = torchtext.vocab.GloVe(name=\"840B\", dim=300)\n",
    "\n",
    "model = TDParser2(pose_set_dim=len(pose_set), pos_embedding_dim=cfg.pos_embedding_dim, glove_dim=300, tagset_dim=len(tagset), combine=\"concatenate\")\n",
    "model.to(cfg.DEVICE)\n",
    "\n",
    "model.load_state_dict(torch.load(\"checkpoints/c_840b300_lr_0_0001/save/model_val.torch\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_parse_tree(model, parse_data, pose_set, glove, device, reverse_tagset):\n",
    "    words_labels = dl.convert_sentence_to_labels(parse_data[\"words\"])\n",
    "    init_stack = []\n",
    "    init_buffer = [state.Token(idx=words_labels[parse_data[\"words\"][i]], word=parse_data[\"words\"][i], pos=parse_data[\"pos\"][i]) for i in range(len(parse_data[\"words\"]))]\n",
    "    init_dependencies = []\n",
    "    ps = state.ParseState(stack=init_stack, parse_buffer=init_buffer, dependencies=init_dependencies)\n",
    "    \n",
    "\n",
    "    pred_actions = []\n",
    "\n",
    "    max_num_actions = 2*len(parse_data[\"words\"]) - 1\n",
    "\n",
    "    while state.is_final_state(ps, cwindow=2) == False:# and max_num_actions > 0:\n",
    "\n",
    "        sw, sp = dl.get_stack(ps.stack)\n",
    "        bw, bp = dl.get_buffer(ps.parse_buffer)\n",
    "\n",
    "        in_words = sw + bw\n",
    "        in_pos = sp + bp\n",
    "        pos_labels = torch.tensor(np.array([pose_set[pos] for pos in in_pos])).unsqueeze(0).to(device)\n",
    "        word_embeds = glove.get_vecs_by_tokens(in_words).unsqueeze(0).to(device)\n",
    "\n",
    "        pred_action_probs = model(word_embeds, pos_labels)\n",
    "\n",
    "        ## get top k predictions\n",
    "        _ , top_indices = torch.topk(pred_action_probs, 2)\n",
    "        top_indices = top_indices.squeeze()\n",
    "        current_action = reverse_tagset[top_indices[0].item()]\n",
    "\n",
    "        ## solve for illegal actions\n",
    "        if \"REDUCE\" in current_action and len(ps.stack) <= 1:\n",
    "            current_action = \"SHIFT\"\n",
    "        elif \"SHIFT\" in current_action and len(ps.parse_buffer) < 1:\n",
    "            current_action = reverse_tagset[top_indices[1].item()]\n",
    "\n",
    "        if \"REDUCE_L\" in current_action:\n",
    "            state.left_arc(ps, current_action[9:])\n",
    "        elif \"REDUCE_R\" in current_action:\n",
    "            state.right_arc(ps, current_action[9:])\n",
    "        else:\n",
    "            state.shift(ps)\n",
    "            \n",
    "        pred_actions.append(current_action)\n",
    "\n",
    "        max_num_actions -= 1\n",
    "\n",
    "    return ps, pred_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s:Appreciation, t:Aesthetic, l:amod\n",
      "s:Art, t:Spanish, l:amod\n",
      "s:Art, t:and, l:cc\n",
      "s:Appreciation, t:Art, l:nmod\n",
      "s:Appreciation, t::, l:punct\n"
     ]
    }
   ],
   "source": [
    "### Train Example for checking the sanity\n",
    "parse_data = {}\n",
    "parse_data[\"words\"] = [\"Aesthetic\", \"Appreciation\", \"and\", \"Spanish\", \"Art\", \":\"]\n",
    "parse_data[\"pos\"] = [\"ADJ\", \"NOUN\", \"CCONJ\", \"ADJ\", \"NOUN\", \"PUNCT\"]\n",
    "ps, _ = run_parse_tree(model, parse_data, pose_set, glove, cfg.DEVICE, reverse_tagset)\n",
    "for d in ps.dependencies:\n",
    "    print(f\"s:{d.source.word}, t:{d.target.word}, l:{d.label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s:lamb, t:little, l:amod\n",
      "s:lamb, t:a, l:det\n",
      "s:lamb, t:had, l:aux\n",
      "s:lamb, t:Mary, l:nmod\n",
      "s:lamb, t:., l:punct\n"
     ]
    }
   ],
   "source": [
    "parse_data = {}\n",
    "parse_data[\"words\"] = [\"Mary\", \"had\", \"a\", \"little\", \"lamb\", \".\" ]\n",
    "parse_data[\"pos\"] = [\"PROPN\", \"AUX\", \"DET\", \"ADJ\", \"NOUN\", \"PUNCT\"]\n",
    "ps, _ = run_parse_tree(model, parse_data, pose_set, glove, cfg.DEVICE, reverse_tagset)\n",
    "for d in ps.dependencies:\n",
    "    print(f\"s:{d.source.word}, t:{d.target.word}, l:{d.label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s:ate, t:I, l:nsubj\n",
      "s:fish, t:the, l:det\n",
      "s:raw, t:fish, l:nsubj\n",
      "s:ate, t:raw, l:conj\n",
      "s:ate, t:., l:punct\n"
     ]
    }
   ],
   "source": [
    "parse_data = {}\n",
    "parse_data[\"words\"] = [\"I\", \"ate\", \"the\", \"fish\", \"raw\", \".\"]\n",
    "parse_data[\"pos\"] = [\"PRON\", \"VERB\", \"DET\", \"NOUN\", \"ADJ\", \"PUNCT\"]\n",
    "ps, _ = run_parse_tree(model, parse_data, pose_set, glove, cfg.DEVICE, reverse_tagset)\n",
    "for d in ps.dependencies:\n",
    "    print(f\"s:{d.source.word}, t:{d.target.word}, l:{d.label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s:networks, t:neural, l:amod\n",
      "s:networks, t:With, l:case\n",
      "s:networks, t:,, l:punct\n",
      "s:love, t:I, l:nsubj\n",
      "s:solving, t:problems, l:obj\n",
      "s:love, t:solving, l:advcl\n",
      "s:networks, t:love, l:acl\n",
      "s:networks, t:., l:punct\n"
     ]
    }
   ],
   "source": [
    "parse_data = {}\n",
    "parse_data[\"words\"] = [\"With\", \"neural\", \"networks\", \",\", \"I\", \"love\", \"solving\", \"problems\", \".\"]\n",
    "parse_data[\"pos\"] = [\"ADP\", \"ADJ\", \"NOUN\", \"PUNCT\", \"PRON\", \"VERB\", \"VERB\", \"NOUN\", \"PUNCT\"]\n",
    "ps, _ = run_parse_tree(model, parse_data, pose_set, glove, cfg.DEVICE, reverse_tagset)\n",
    "for d in ps.dependencies:\n",
    "    print(f\"s:{d.source.word}, t:{d.target.word}, l:{d.label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get output on hidden dataset\n",
    "hidden_dataset = dl.ParsingDatasetEval(data_file=cfg.hidden_data_path, pose_set=pose_set, tagset=tagset, glove=glove, split='hidden')\n",
    "\n",
    "hidden_loader = DataLoader(\n",
    "    hidden_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    collate_fn=dl.custom_collate_fn,\n",
    "    pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "util.run_hidden_data(model, hidden_loader, reverse_tagset, \"results.txt\", cfg.DEVICE, complete=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
